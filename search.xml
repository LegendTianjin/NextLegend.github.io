<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[机器学习Day4]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F10%2F04%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Day4%2F</url>
    <content type="text"><![CDATA[Day4逻辑回归之基本概念&#160; &#160; &#160; &#160;先给大家看一下逻辑回归的基本概念哈，大家先对这个有一个直观的认识就好，看不懂或者不明白没关系哈，后面小亮会一点一点给大家答疑解惑，拨开云雾，柳暗花明哈。逻辑回归如下面这幅图片所示： 一、直观概念&#160; &#160; &#160; &#160;逻辑回归，英文为logistic，又称logistic回归分析，是一种广义的线性回归分析模型，常用于数据挖掘，疾病自动诊断，经济预测等领域。例如，以胃癌病情分析为例，选择两组人群，一组是胃癌组，一组是非胃癌组，两组人群必定具有不同的体征与生活方式等。因此因变量就为是否胃癌，值为“是”或“否”，自变量就可以包括很多了，如年龄、性别、饮食习惯、幽门螺杆菌感染等。自变量既可以是连续的，也可以是分类的。然后通过logistic回归分析，可以得到自变量的权重，从而可以大致了解到底哪些因素是胃癌的危险因素。同时根据该权值可以根据危险因素预测一个人患癌症的可能性。 二、数学概念&#160; &#160; &#160; &#160;logistic回归是一种广义线性回归（generalized linear model），因此与多重线性回归分析有很多相同之处。它们的数学模型形式基本上相同，都具有 w‘x+b，其中w和b是待求参数，其区别在于他们的因变量不同，多重线性回归直接将w‘x+b作为因变量，即y =w‘x+b，而logistic回归则通过函数L将w‘x+b对应一个隐状态p，p =L(w‘x+b),然后根据p 与1-p的大小决定因变量的值。如果L是logistic函数，就是logistic回归，如果L是多项式函数就是多项式回归 三、小亮总结&#160; &#160; &#160; &#160;逻辑回归其实就是这样的一个过程：面对一个回归或者分类问题，建立代价函数，然后通过优化方法迭代求解出最优的模型参数，然后测试验证我们这个求解的模型的好坏。Logistic回归虽然名字里带“回归”，但是它实际上是一种分类方法，主要用于两分类问题（即输出只有两种，分别代表两个类别）回归模型中，y是一个定性变量，比如y=0或1，logistic方法主要应用于研究某些事件发生的概率。 四、常用的logistic函数&#160; &#160; &#160; &#160;sigmoid函数为常用的logistic函数，数学公式如下图所示：&#160; &#160; &#160; &#160;小亮再用代码给大家画一下这个函数： #coding:utf-8 import matplotlib.pyplot as plt import numpy as np def Sigmoid(x): return 1.0 / (1.0 + np.exp(-x)) x = np.arange(-20, 20, 0.1) h = Sigmoid(x) # Sigmoid函数 plt.plot(x, h,color=&apos;red&apos;) plt.axvline(0.0, color=&apos;k&apos;) # 坐标轴上加一条竖直的线（0位置） plt.axhspan(0.0, 1.0, facecolor=&apos;1.0&apos;, alpha=1.0, ls=&apos;dotted&apos;) plt.axhline(y=0.5, ls=&apos;dotted&apos;, color=&apos;k&apos;) plt.yticks([0.0, 0.5, 1.0]) # y轴标度 plt.ylim(-0.1, 1.1) # y轴范围 plt.show()]]></content>
      <categories>
        <category>Machine_Learning Python</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018知识图谱发展报告之小亮见解]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F10%2F02%2F2018%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%8F%91%E5%B1%95%E6%8A%A5%E5%91%8A%E4%B9%8B%E5%B0%8F%E4%BA%AE%E8%A7%81%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[2018知识图谱发展报告之小亮见解&#160; &#160; &#160; &#160;先给大家把此次2018知识图谱的发展报告PDF版送上，封面如下面这幅图片所示：百度云链接为：链接：https://pan.baidu.com/s/1qI7pYp03NOTL4V9cQ9GV2g 密码：kewf&#160; &#160; &#160; &#160;下面是这份知识图谱的目录和编写人员，可以看到大多数是领域内知名专家和教授，比如小亮目前所在的事件检测方向的赵军老师和他的学生陈玉博老师等等。&#160; &#160; &#160; &#160;小亮对这份知识图谱领域的发展报告大致看了一遍，其中对于第五章《事件知识学习》看的比较详细，因为目前小亮对这个领域内的任务比较明确，下面就讲讲小亮之所见吧。&#160; &#160; &#160; &#160;事件识别和抽取研究如何从描述事件信息的文本中识别并抽取出事件信息并以结构化的形式呈现出来，包括其发生的时间、地点、参与角色以及与之相关的动作或者状态的改变，核心的概念如下图所示：&#160; &#160; &#160; &#160;事件检测与追踪旨在将文本新闻流按照其报道的事件进行组织，为传统媒体多种来源的新闻监控提供核心技术，以便让用户了解新闻及其发展。具体而言，事件发现与跟踪包括三个主要任务：分割，发现和跟踪，将新闻文本分解为事件，发现新的（不可预见的）事件，并跟踪以前报道事件的发展。事件发现任务又可细分为历史事件发现和在线事件发现两种形式，前者目标是从按时间排序的新闻文档中发现以前没有识别的事件，后者则是从实时新闻流中实时发现新的事件。 数据集&#160; &#160; &#160; &#160;现在不论是自然语言处理领域，还是计算机视觉领域，都热衷于神经网络Embedding方法，自然少不了对于数据集的选取。那么，Event Detection领域的标准数据集是ACE2005语料。详细的语料介绍如下所示：&#160; &#160; &#160; &#160;ACE语料是需要花钱买的，现在网上是找不到免费的语料的。出于对中文事件语料Chinese Event Corpus, CEC的好奇，小亮找到了这个语料(大家如果做研究用，可以免费下载哈！)： 链接如下：https://github.com/shijiebei2009/CEC-Corpus&#160; &#160; &#160; &#160;中文突发事件语料库是由上海大学（语义智能实验室）所构建。根据国务院颁布的《国家突发公共事件总体应急预案》的分类体系，从互联网上收集了5类（地震、火灾、交通事故、恐怖袭击和食物中毒）突发事件的新闻报道作为生语料，然后再对生语料进行文本预处理、文本分析、事件标注以及一致性检查等处理，最后将标注结果保存到语料库中，CEC合计332篇。 技术路线&#160; &#160; &#160; &#160;事件抽取当前技术路线为基于模识匹配的事件抽取和基于机器学习的事件抽取。其中，基于模识匹配的事件抽取是基于传统的方法来做，需要定义模式和规则，比较严谨，在特定领域中性能较好，表示简洁，但对于语言、领域和文档形式等均有不同程度的依赖，覆盖度和可移植性较差。基于机器学习的方法建立在统计模型基础上，一般将事件抽取建模成多分类问题，因此研究的重点在于特征和分类器的选择。这块将局部信息与全局信息的融合思想，小亮觉得可以重点研究一下可行性问题和性能，这个idea还是不错的。 机遇与挑战&#160; &#160; &#160; &#160;目前国内外事件抽取相关的研究大部分都是面向英文文本的英文事件抽取，面向中文文本的中文事件抽取工作才刚刚起步，主要面临技术和数据两方面的挑战。技术层面，中文的词句是意合的，词语间没有显式分隔符，而且中文实词在时态和形态上也没有明显变化， 因此面向中文的事件抽取研究在基础自然语言处理层面具有天然的劣势。 数据层面， 由于起步较晚，缺乏统一的、公认的语料资源和相关评测，极大制约了中文事件抽取的研究。尽管如此，近些年中文事件抽取在公开评测、领域扩展和跨预料迁移方面也取得一定进展。所以，小亮觉得，中文场景下的事件抽取拥有更大的发展潜力与空间，以后小亮还会持续关注这个了领域的。 小亮说&#160; &#160; &#160; &#160;最后，小亮觉得知识图谱也是这两年一下就火起来了，还处于一个萌芽的阶段，对这个领域的技术小亮心里还抱有迟疑的感觉，不过未来知识图谱的发展一定是空前的，可能三五年后吧，知识图谱将会改变传统的搜索引擎的模式，领域内知识图谱会更多，更成熟，这也是一个非常好的机会。明天或者后天小亮会实践一下知识图谱这个领域的技术，切身感受一下它的威力。以上就是小亮对于2018年知识图谱发展报告的一个小小的感受，欢迎大家交流哈！]]></content>
      <categories>
        <category>自然语言处理 知识图谱 Knowledge_Graph</category>
      </categories>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习Day3]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F09%2F30%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Day3%2F</url>
    <content type="text"><![CDATA[Day3多元线性回归&#160; &#160; &#160; &#160;先给大家看一下这一部分的流程哈，主要分为3个Step，如下面这幅图片所示： #coding:utf-8 # 导入库 import pandas as pd import numpy as np #Step1: 导入数据集 dataset = pd.read_csv(‘50_Startups.csv’) X = dataset.iloc[ : , :-1].values Y = dataset.iloc[ : , 4 ].values # Step2: 将类别数据数字化 from sklearn.preprocessing import LabelEncoder, OneHotEncoder labelencoder = LabelEncoder() X[: , 3] = labelencoder.fit_transform(X[ : , 3]) onehotencoder = OneHotEncoder(categorical_features = [3]) X = onehotencoder.fit_transform(X).toarray() #Step3:躲避虚拟变量陷阱 X = X[: , 1:] # 拆分数据集为训练集和测试集 from sklearn.model_selection import train_test_split X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0) # 第2步： 在训练集上训练多元线性回归模型 from sklearn.linear_model import LinearRegression regressor = LinearRegression() regressor.fit(X_train, Y_train) # Step4: 在测试集上预测结果 y_pred = regressor.predict(X_test) print(y_pred)测试集上预测结果]]></content>
      <categories>
        <category>Machine_Learning Python</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习Day2]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F09%2F28%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Day2%2F</url>
    <content type="text"><![CDATA[Day2简单线性回归&#160; &#160; &#160; &#160;先给大家看一下这一部分的流程哈，主要分为4个Step，如下面这幅图片所示： #coding:utf-8 import pandas as pd import numpy as np import matplotlib.pyplot as plt #Step1:数据预处理 dataset = pd.read_csv(‘studentscores.csv’) X = dataset.iloc[ : , : 1 ].values Y = dataset.iloc[ : , 1 ].values from sklearn.model_selection import train_test_split X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size = 1/4, random_state = 0) #Step2:训练集使用简单线性回归模型来训练 from sklearn.linear_model import LinearRegression regressor = LinearRegression() regressor = regressor.fit(X_train, Y_train) #Step3：预测结果 Y_pred = regressor.predict(X_test) #Step4:可视化 #训练集结果可视化 plt.scatter(X_train , Y_train, color = ‘red’) plt.plot(X_train , regressor.predict(X_train), color =’blue’) plt.show() #测试集结果可视化 plt.scatter(X_test , Y_test, color = ‘red’) plt.plot(X_test , regressor.predict(X_test), color =’blue’) plt.show()&#160; &#160; &#160; &#160;将上面的代码输入到编辑器中，执行，就会得到下面的结果，因为我们调用Matplotlib画图函数，所以我们可以得到可视化之后的结果，如下图所示：。训练集结果可视化测试集结果可视化]]></content>
      <categories>
        <category>Machine_Learning Python</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习Day1]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F09%2F27%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Day1%2F</url>
    <content type="text"><![CDATA[Day1数据预处理&#160; &#160; &#160; &#160;先给大家看一下这一部分的流程哈，主要分为6个Step，如下面这幅图片所示： #coding:utf-8 #Day 1: Data Prepocessing #Step 1: Importing the libraries import numpy as np import pandas as pd #Step 2: Importing dataset dataset = pd.read_csv(&apos;Data.csv&apos;) X = dataset.iloc[ : , :-1].values Y = dataset.iloc[ : , 3].values print(&quot;Step 2: Importing dataset&quot;) print(&quot;X&quot;) print(X) print(&quot;Y&quot;) print(Y) #Step 3: Handling the missing data from sklearn.preprocessing import Imputer imputer = Imputer(missing_values = &quot;NaN&quot;, strategy = &quot;mean&quot;, axis = 0) imputer = imputer.fit(X[ : , 1:3]) X[ : , 1:3] = imputer.transform(X[ : , 1:3]) print(&quot;---------------------&quot;) print(&quot;Step 3: Handling the missing data&quot;) print(&quot;step2&quot;) print(&quot;X&quot;) print(X) #Step 4: Encoding categorical data from sklearn.preprocessing import LabelEncoder, OneHotEncoder labelencoder_X = LabelEncoder() X[ : , 0] = labelencoder_X.fit_transform(X[ : , 0]) #Creating a dummy variable onehotencoder = OneHotEncoder(categorical_features = [0]) X = onehotencoder.fit_transform(X).toarray() labelencoder_Y = LabelEncoder() Y = labelencoder_Y.fit_transform(Y) print(&quot;---------------------&quot;) print(&quot;Step 4: Encoding categorical data&quot;) print(&quot;X&quot;) print(X) print(&quot;Y&quot;) print(Y) #Step 5: Splitting the datasets into training sets and Test sets from sklearn.model_selection import train_test_split X_train, X_test, Y_train, Y_test = train_test_split( X , Y , test_size = 0.2, random_state = 0) print(&quot;---------------------&quot;) print(&quot;Step 5: Splitting the datasets into training sets and Test sets&quot;) print(&quot;X_train&quot;) print(X_train) print(&quot;X_test&quot;) print(X_test) print(&quot;Y_train&quot;) print(Y_train) print(&quot;Y_test&quot;) print(Y_test) #Step 6: Feature Scaling from sklearn.preprocessing import StandardScaler sc_X = StandardScaler() X_train = sc_X.fit_transform(X_train) X_test = sc_X.transform(X_test) print(&quot;---------------------&quot;) print(&quot;Step 6: Feature Scaling&quot;) print(&quot;X_train&quot;) print(X_train) print(&quot;X_test&quot;) print(X_test) &#160; &#160; &#160; &#160;将上面的代码输入到编辑器中，执行，就会得到下面的结果，大家先看看结果是不是和小亮一样哈，后面我们再解说一下数据处理的详细过程。 G:\Code\Python_Learn\Study_Tensorflow_2018\venv\Scripts\python.exe &quot;G:/Code/Python_Learn/Study_Tensorflow_2018/venv/Machine Learning 100 days/day1/day1.py&quot; Step 2: Importing dataset X [[&apos;France&apos; 44.0 72000.0] [&apos;Spain&apos; 27.0 48000.0] [&apos;Germany&apos; 30.0 54000.0] [&apos;Spain&apos; 38.0 61000.0] [&apos;Germany&apos; 40.0 nan] [&apos;France&apos; 35.0 58000.0] [&apos;Spain&apos; nan 52000.0] [&apos;France&apos; 48.0 79000.0] [&apos;Germany&apos; 50.0 83000.0] [&apos;France&apos; 37.0 67000.0]] Y [&apos;No&apos; &apos;Yes&apos; &apos;No&apos; &apos;No&apos; &apos;Yes&apos; &apos;Yes&apos; &apos;No&apos; &apos;Yes&apos; &apos;No&apos; &apos;Yes&apos;] --------------------- Step 3: Handling the missing data step2 X [[&apos;France&apos; 44.0 72000.0] [&apos;Spain&apos; 27.0 48000.0] [&apos;Germany&apos; 30.0 54000.0] [&apos;Spain&apos; 38.0 61000.0] [&apos;Germany&apos; 40.0 63777.77777777778] [&apos;France&apos; 35.0 58000.0] [&apos;Spain&apos; 38.77777777777778 52000.0] [&apos;France&apos; 48.0 79000.0] [&apos;Germany&apos; 50.0 83000.0] [&apos;France&apos; 37.0 67000.0]] --------------------- Step 4: Encoding categorical data X [[1.00000000e+00 0.00000000e+00 0.00000000e+00 4.40000000e+01 7.20000000e+04] [0.00000000e+00 0.00000000e+00 1.00000000e+00 2.70000000e+01 4.80000000e+04] [0.00000000e+00 1.00000000e+00 0.00000000e+00 3.00000000e+01 5.40000000e+04] [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.80000000e+01 6.10000000e+04] [0.00000000e+00 1.00000000e+00 0.00000000e+00 4.00000000e+01 6.37777778e+04] [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.50000000e+01 5.80000000e+04] [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.87777778e+01 5.20000000e+04] [1.00000000e+00 0.00000000e+00 0.00000000e+00 4.80000000e+01 7.90000000e+04] [0.00000000e+00 1.00000000e+00 0.00000000e+00 5.00000000e+01 8.30000000e+04] [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.70000000e+01 6.70000000e+04]] Y [0 1 0 0 1 1 0 1 0 1] --------------------- Step 5: Splitting the datasets into training sets and Test sets X_train [[0.00000000e+00 1.00000000e+00 0.00000000e+00 4.00000000e+01 6.37777778e+04] [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.70000000e+01 6.70000000e+04] [0.00000000e+00 0.00000000e+00 1.00000000e+00 2.70000000e+01 4.80000000e+04] [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.87777778e+01 5.20000000e+04] [1.00000000e+00 0.00000000e+00 0.00000000e+00 4.80000000e+01 7.90000000e+04] [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.80000000e+01 6.10000000e+04] [1.00000000e+00 0.00000000e+00 0.00000000e+00 4.40000000e+01 7.20000000e+04] [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.50000000e+01 5.80000000e+04]] X_test [[0.0e+00 1.0e+00 0.0e+00 3.0e+01 5.4e+04] [0.0e+00 1.0e+00 0.0e+00 5.0e+01 8.3e+04]] Y_train [1 1 1 0 1 0 0 1] Y_test [0 0] --------------------- Step 6: Feature Scaling X_train [[-1. 2.64575131 -0.77459667 0.26306757 0.12381479] [ 1. -0.37796447 -0.77459667 -0.25350148 0.46175632] [-1. -0.37796447 1.29099445 -1.97539832 -1.53093341] [-1. -0.37796447 1.29099445 0.05261351 -1.11141978] [ 1. -0.37796447 -0.77459667 1.64058505 1.7202972 ] [-1. -0.37796447 1.29099445 -0.0813118 -0.16751412] [ 1. -0.37796447 -0.77459667 0.95182631 0.98614835] [ 1. -0.37796447 -0.77459667 -0.59788085 -0.48214934]] X_test [[-1. 2.64575131 -0.77459667 -1.45882927 -0.90166297] [-1. 2.64575131 -0.77459667 1.98496442 2.13981082]] Process finished with exit code 0 &#160; &#160; &#160; &#160;上面就是今天的机器学习Day1的内容，大家重点了解一下Numpy、Pandas、Sklearn这三个库的使用和数据处理部分。]]></content>
      <categories>
        <category>Machine_Learning Python</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习100天]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F09%2F27%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0100%E5%A4%A9%2F</url>
    <content type="text"><![CDATA[机器学习100天&#160; &#160; &#160; &#160;小亮接触深度学习也将近一年了，通过走了这么多的路，读论文也好，看视频也好，看书也好，发现还是得通过边敲代码边思考边理解公式这样的方式比较踏实，不然就是天马行空，吹吹牛罢了！你会什么？我会深度学习耶！那你给我写两行代码解决一下这个问题？感知机是什么？交叉熵损失函数是什么？反向转播算法来推导一下？Pandas、Numpy、Scikit-learn这些库用过吗？当面试官或者HR问起这些的时候，我希望小亮或者你们能够胸有成竹的说，这些我都会哈，来我给你手工推导一下交叉熵损失函数是如何影响网络的学习速率的，反向传播算法是根据微积分的链式求导罚则调节参数权重w和偏置b的，这个项目我做过，那个我也知道。。。。。。其实，这个时候这种状态才是小亮应有的状态，希望在2020年毕业的时候，再回到此处时，可以做到无悔于时间、无悔于现在所做的一切与努力。每天进步一点点，来跟着小亮Machine Learning吧！&#160; &#160; &#160; &#160;上面的是机器学习100天的每天的内容，从今天开始，小亮将会身体力行的实践，边思考边前行边总结边记录每一天的成长与收获！欢迎各位小伙伴与小亮一起前行，不断地打怪升级！]]></content>
      <categories>
        <category>Machine_Learning Python</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NLP事件检测基本概念]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F09%2F25%2FNLP%E4%BA%8B%E4%BB%B6%E6%A3%80%E6%B5%8B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[自然语言处理之事件检测一、什么是NLP&#160; &#160; &#160; &#160;nlp是自然语言处理，是电脑理解并表达出人们平常的所说的语言二、nlp的事件抽取是什么？&#160; &#160; &#160; &#160;事件抽取是从非结构信息中抽取出用户感兴趣的信息，并以结构化数据传递给用户。三、事件抽取所处的位置？&#160; &#160; &#160; &#160;事件抽取是信息抽取的一部分。事件抽取的又分为元事件抽取和主题事件抽取。元事件抽取是动作状态级的，动作产生或状态发生变化，一般由动词驱动。主题事件抽取是事件级的，一类核心事件或活动以及与他们相关的事件和活动。四、事件抽取的研究方法有哪些？&#160; &#160; &#160; &#160;事件抽取的研究方法有模式匹配和机器学习两种。模式匹配只针对特定领域，移植性差。机器学习应用广泛，移植性好。五、模式匹配方法如何进行事件抽取？&#160; &#160; &#160; &#160;模式匹配方法是在一定模式的指导下进行事件的识别和抽取。模式：指的是抽取模式。通过领域知识和语言知识对目标信息的上下文环境进行约束。而这约束条件就是抽取模式。另外模式是手工建立的，耗时又费力，所以现在用的都是机器学习方法的事件抽取。六、机器学习方法如何进行事件抽取？&#160; &#160; &#160; &#160;对元事件抽取两大主要任务：对事件识别与分类和对事件元素进行识别和分类。事件元素识别和分类是事件识别和分类的基础。有关论文显示：机器学习算法混合使用将优于单一算法。事件的探测分两种实现方式：基于触发词的探测方式和基于事件的事例的探测方式。&#160; &#160; &#160; &#160;基于触发词的探测方式：&#160; &#160; &#160; &#160;基于触发词的探测方式的有正反例不平衡和数据稀疏的缺点。因为只有少量触发词作为输入数据进行训练，大量未参与进来的。作为反例数据参与到模型中，造成正反例不平衡，触发词数据稀疏。解决触发词探测缺点的方法：通过同义词扩展和二分类结合的方法进行解决，即将触发词放入词典中进行同义词扩展。&#160; &#160; &#160; &#160;基于事件实例的探测方式：&#160; &#160; &#160; &#160;基于事件实例的探测方式是将句子而不是词语作为识别实例。进而通过聚类方法转化为句子聚类问题，通过聚类得到事件句。避开了基于触发词探测的缺点。七、基于机器学习方法抽取方式的特点？&#160; &#160; &#160; &#160;(1) 机器学习方法的优点是自动获取模式。&#160; &#160; &#160; &#160;(2) 机器学习方法不基于语料的格式和内容，但需要大量标准预料（解决方法:无监督和半监督的方法）]]></content>
      <categories>
        <category>NLP Event Detection</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[这里的人与这里的故事]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F09%2F09%2F%E8%BF%99%E9%87%8C%E7%9A%84%E4%BA%BA%E4%B8%8E%E8%BF%99%E9%87%8C%E7%9A%84%E6%95%85%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[&#160; &#160; &#160; &#160;在记录自己今天的感受前，先来介绍一下我大学仅有的几个好朋友之一———&gt;老郭（也就是今天的主人公李同学）！我和老郭的认识源于电子设计比赛，认知于电子设计比赛，结交于电子设计比赛，虽然我们不是一个班的，但是我们在很多问题上交流的很多，从他身上也学到了很多为人处世的道理——&gt;谦逊、踏实、担当，还有感恩！&#160; &#160; &#160; &#160;早上十点钟我们本来约定在大学城地铁站见面，但是很巧的是，在营口道转3号线的时候，小亮竟然与老郭完美的偶遇于一趟车的相邻车厢。（这就是缘分！哈哈！）上车后第一眼就看到了他，远远地看去，瘦了一圈，可能是来自于工作的压力人就会瘦吧！身穿一件深灰色的衬衣与牛仔裤，戴着耳机，（程序员可能都是这样的装备吧！）也在寻觅着我。老郭还是老郭，还是那样的幽默风趣，还是那样的思考着前行着前行着而又思考着，其实小亮心里一直挺为他惋惜的，但是一直又鼓励着他，让他自信起来，相信自己，不要因为过去的事带着自卑的情绪而影响现在的自己，因为你值得更好地未来，没错，你值得！！！我们俩就像失散多年的老友一样，还是当年的那个老郭与于谦，相谈甚欢。&#160; &#160; &#160; &#160;到了大学城地铁站，我建议骑个小黄去学院吧，老郭说咱们走过去吧，我说好，这样也可以用脚步重新再走一遍这个地方。于是，我们就顶着今天的太阳，感受着校庆60周年的余热，北门的一句“欢迎校友回家”甚是暖心，是啊，才毕业不到三个月的我们，已然是这所大学的校友，感叹时间过得如此的飞快，老郭突然冒出一句：“下一次回到这里就不知道是什么时候了，或许在十年后吧！”我紧接着附和道：“是啊，可能是十年后了吧！”之所以与老郭的关系不断深入，就是因为知道他的每一句话背后的故事，以及他在想什么，而他所想的同时也是我想的，或许这就是我们能够说到一块的原因吧。此刻，他又在感叹，感叹曾经的故事！走在宽大的校园马路上，随处可见工大60周年校庆的牌子，还挺美的，与大家分享一下哈！&#160; &#160; &#160; &#160;走到这里的时候，突然有三四个中年阿姨，问我们：“同学，你知道校史馆怎么走吗？”我和老郭给这些校友前辈指了校史馆的位置，老郭说要不咱们也去看看吧，之前我没去过，我说好。就这样，我们作为年轻校友在前面给校友前辈带路，到了校史馆，我和老郭在前面观看学校的历史与珍贵的仪器，顺便听讲着学生讲解员给她们的讲解。在走到一台上了年纪的纺织仪器面前，老郭出于一贯的质疑与好奇思维，尝试着搞明白它的机械原理（被我偷拍了，哈哈）&#160; &#160; &#160; &#160;还有这个—————&gt;&#160; &#160; &#160; &#160;在经过时间里程计的时候，我突然握住老郭的大手，我说一起见证这伟大的时刻吧，而老郭突然配乐道：“当当当当。。。。。。”我禁不住笑了起来，你这是瓦格纳的《婚礼进行曲》啊，有点尴尬，哈哈。&#160; &#160; &#160; &#160;参观完校史馆，我们迫不及待的赶紧前往学院，先去了老师办公室，结果发现没人，可能是周末的原因吧。。。。。。。。然后我们就去考研自习室找了会煜大神，时间也十一点了，我们商量着要不先去吃饭去吧，就边走边聊，老郭和会煜大神谈起来更是津津有味，他们两更是同道中人。（这次回来，发现大家都没怎么变，还是老样子，真切、幽默、调侃、又互相关心着彼此的发展，或许这就是好朋友最真的面貌吧！）吃饭回来在学院一楼又聊了聊，聊到了过去，聊到了现在，还聊到了未来。&#160; &#160; &#160; &#160;聊到了大概十二点半左右，我和老郭看着时间也不早了，不能影响了会煜大神的节奏，我们就与他告别离开了，希望今年他能够考上自己心仪的学校，也是我们专业，甚至学院最有希望与能力的。其实，自己从他那里也学到了很多很多，做事态度认真，求真务实、追求完美、说话只说自己很有把握的话，给人一种非常踏实的感觉与印象，就是每一件事都交给他，让人很放心，而且他不仅会完成任务，而且还会给你优化与一些建议，这就是他，会煜大神，关于他的故事已然成为我们专业，乃至学院的神话，人人皆知，人人皆视其为榜样！&#160; &#160; &#160; &#160;再后来，我和老郭联系了一下老师，老师说他刚到办公室，我们去办公室找他，就这样，我和老郭准备了半个小时就去看望老师了。和老师谈了两三个小时，谈到了过去，谈到了现在，谈到了未来。谈到了学业、谈到了工作、谈到了个人理想。老郭又有些感触了，(我总觉得他有些不甘心，有些自卑)老师似乎也发现了，就鼓励他说其实做技术积累个两三年也挺好的，现在的研究生动手能力太差了，连最基本的仪器都不会使用，到时候找工作就不如你们这些已经工作了两三年的，只是他们起点比你们现在高罢了，老郭听后觉得也有道理，目光些许明亮起来，给老师说，他有这个自信能够在单位里做好。（以老郭的能力与思维能力，我相信三五年后，或许我该叫他李所或者李部长了。）后来又和老师聊了很多，老师也相应的给了一些建议，让我们不管在社会上还是学校里，都要实事求是，踏踏实实做技术，规划好自己的时间与人生，该来的总会来的，要懂得隐忍与坚守！！！&#160; &#160; &#160; &#160;四点左右，我和老郭看着时间不早了，也不想打扰老师工作（周末老师还来实验室，可见他的敬业与乐业精神所在）我们就和老师道别后，离开了。&#160; &#160; &#160; &#160;最后想说，自己虽然现在已是一名研究生了，两年半后自己也面临着找工作，进入社会这个象牙塔，到时候是以怎样的姿态以及怎样的精神面貌迎接那时候的社会与工作，全在这不到三年里的每一天的进步与成长，就像老郭一样，思考着前行着前行着而又思考着，生活就是这样。人生路上能够遇到这样的恩师很难得，也很庆幸自己能够在求学路上遇见很多这样的恩师，古语云：“十年树木，百年树人；插柳之恩；终生难忘！”最后，明天是教师节，提前预祝天下的所有教师节日快乐！ ——2018年9月9日夜晚 于天津大学北洋园]]></content>
      <categories>
        <category>朋友 人生导师</category>
      </categories>
      <tags>
        <tag>人生路上的朋友</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算图上的微积分：反向传播]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F09%2F05%2F%E8%AE%A1%E7%AE%97%E5%9B%BE%E4%B8%8A%E7%9A%84%E5%BE%AE%E7%A7%AF%E5%88%86%EF%BC%9A%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%2F</url>
    <content type="text"><![CDATA[一、介绍反向传播是一种关键的算法，它可以使训练深度模型在计算上易于处理。对于现代神经网络来说，相对于一个简单的实现，它可以使梯度下降的训练速度达到1000万倍。这就是一周训练和用20万年时间训练的模型之间的区别。除了在深度学习中使用之外，反向传播在许多其他领域是一个强大的计算工具，从天气预报到分析数字稳定性，它只是在不同的领域用不同的名字。事实上，该算法在不同的领域至少被重新改造了几十次（见Griewank（2010））。一般，应用程序独立，名称是“反向模式区分”。从根本上说，这是一种快速计算微分的技术。在你的包里，这是一个很重要的技巧，不仅在深度学习中，而且在各种各样的数字计算环境中。二、计算图计算图是一种思考数学表达式的好方法。例如，考虑表达式e =(a + b)∗(b + 1)。这里有三个操作：两个加法和一个乘法。为了帮助我们讨论这个问题，让我们引入两个中间变量，c和d，所以每个函数的输出都有一个变量。我们现在有: c=a + b d=b + 1 e=c * d为了创建一个计算图，我们将这些操作连同输入变量一起放入节点。当一个节点的值是另一个节点的输入时，一个箭头从一个节点到另一个节点。在计算机科学中，这些图表一直都在出现，尤其是在谈论功能程序的时候。它们与依赖关系图和调用图的概念密切相关。它们也是流行的深度学习框架Theano背后的核心抽象。我们可以通过将输入变量设置为特定的值和通过图表计算节点来评估表达式。例如,让我们设置a = 2和b = 1 :表达式的求值结果为6。三、计算图的导数如果想要在计算图中理解导数，关键是要理解导数的边界。如果a直接影响c，然后我们想知道它是如何影响的c。如果a稍微改变一下，那c如何改变?我们称其c是关于a的偏导数。为了求出这张图中的偏导数，我们需要求和规则和乘积法则：下图中每条边都有导数。如果我们想要了解没有直接连接的节点是如何相互影响的呢？让我们考虑一下e是如何被a影响的。如果我们以1的速度改变a，c同样的变化速度1改变。反过来, c以1的速度变化导致e以2的改变速率。所以e变化速率1∗2关于a。一般规则是对从一个节点到另一个节点的所有可能路径求和，将路径的每个边的导数相乘。例如，要得到e关于b的导数。我们得到:这就解释了b是如何影响e到c的，以及它是如何通过d来影响它的。这种一般的“对路径求和”规则只是一种不同的关于多元链式法则的思考方式。四、因式分解路径仅仅“对路径求和”的问题是，在可能的路径中，很容易得到一个组合爆炸。在上面的图中，从X到Y有三条路径，从Y到Z还有三条路径。如果我们想求导∂Z/∂X的话，通过对所有路径求和，我们需要求和3∗3 = 9条道路:上面只有9条路径，但是当图形变得更加复杂时，很容易就会有成倍增长的路径。与其简单地对路径求和，不如把它们因式分解：这就是“前向传播”和“反向传播”。它们是通过分解路径来有效计算总和的算法。它们不是显式地对所有路径求和，而是通过在每个节点上合并路径来更有效地计算相同的总和。事实上，这两种算法都能精确地触碰到每条边！ 前向传播从图的输入开始，然后向末端移动。在每个节点上，它都能计算出所有的路径。每条路径都代表了输入影响该节点的一种方式。通过把它们加起来，我们得到了节点受输入影响的总方式，它是导数。虽然你可能没有从图的角度来考虑它，但是向前模式的微分和你在微积分课上做过的介绍是非常相似的。另一方面，反向传播的微分，从图的输出开始，向开始移动。在每个节点上，它合并了源自该节点的所有路径。前向传播微分研究一个输入如何影响每个节点。反向传播微分研究每个节点如何影响一个输出。也就是说，正向模式微分应用算子∂/∂X对每个节点，反向模式微分应用算子∂Z/∂每一个节点。五、Computational Victories在这一点上，您可能想知道为什么有人会关心反向传播的微分。这看起来像是一种奇怪的方法，可以做与前模一样的事情。有什么好处吗？让我们再来看看我们最初的例子：我们可以使用正向模式的微分b向上，这就给了我们每个结点的导数b。我们计算∂e/∂b，这个导数是我们的输出对我们的输入的导数。如果我们做反向模式的微分从e开始? 这就得到了e对于每个节点的微分。当我说反向传播微分给我们对每个结点的导数时，我确实是指每个结点。我们得到两个∂e/∂a和∂e/∂b，e的导数是关于两个输入。前向传播的微分给了我们输出对单个输入的导数，但是反向模式的微分给了我们所有的结果。对于这个图，这只是两个因子的加速，但是想象一个有上百万个输入和一个输出的函数。前向传播的微分要求我们通过这个图上百万次来得到导数。反向传播的微分可以一下子把它们都弄到手！一个百万分之一的速度是相当不错的！在训练神经网络时，我们考虑的是成本（描述神经网络的糟糕程度）作为参数的函数（描述网络行为的数字）。我们想要计算所有参数的成本的导数，用于梯度下降。现在，在神经网络中，通常有数百万甚至数千万个参数。所以，反向模式的分化，在神经网络的背景下被称为反向传播，给我们一个巨大的速度！（有任何情况下，正向模式的分化更有意义吗？是的,有! 当反向模式给出一个输出对所有输入的导数时，正向模式给出了所有输出对一个输入的导数。如果一个函数有大量的输出，那么正向模式的微分就会大大加快。)六、这不是简单的吗?Isn’t This Trivial?当我第一次理解反向传播的时候，我的反应是：“哦，这就是链式法则！我们怎么花了这么长时间才弄明白？“我不是唯一一个有这种反应的人。”的确，如果你问“在前馈神经网络中有一种聪明的计算导数的方法吗？”“答案并不难。但我认为这比表面上看起来要困难得多。你看，在反向传播发明的时候，人们并不是很关注我们研究的前馈神经网络。同样不明显的是，微分是培训它们的正确方式。一旦你意识到你可以快速计算出导数，这些就很明显了。这是一种循环依赖。更糟糕的是，在不经意的想法中，把循环依赖的任何部分都写下来是很容易的。用微分工具训练神经网络？你肯定会被困在局部最优解里。很明显，计算所有这些导数都很昂贵。这只是因为我们知道这种方法是有效的，我们不会立即开始列出它可能不会的原因。这是事后诸葛亮的好处。一旦你提出了这个问题，最困难的工作就已经完成了。七、结论微分比你想象的要便宜。这是我们从这篇文章中得到的主要教训。事实上，它们的价格并不便宜，而美国愚蠢的人不得不反复发现这一事实。在深度学习中，这是很重要的一点。在其他领域中，这也是一件非常有用的事情，只有当它不是常识的时候才会知道。还有其他的教训吗？我认为有。反向传播也是理解微分如何流经模型的有用工具。这对于解释为什么有些模型很难优化是非常有用的。最典型的例子是在重复的神经网络中消失的梯度问题。最后，我认为从这些技术中可以得到一个广泛的算法教训。反向传播和正向模式的区别使用强大的一对技巧（线性化和动态规划）来比人们想象的更有效地计算导数。如果您真正理解了这些技术，您可以使用它们来有效地计算其他涉及到微分的有趣表达式。我们将在以后的博客文章中探讨这个问题。这篇文章给出了一个非常抽象的反向传播的方法。我强烈建议阅读Michael Nielsen关于它的章节，进行精彩的讨论，更具体地关注神经网络。八、致谢感谢Greg Corrado，Jon Shlens，Samy Bengio和an利亚Angelova，感谢他们花时间校对这篇文章。也要感谢达里奥阿米迪、迈克尔尼尔森和约书亚本吉奥讨论解释反向传播的方法。也要感谢那些在演讲和研讨会系列中允许我练习解释反向传播的人！]]></content>
      <categories>
        <category>计算图 神经网络</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[再谈数据结构]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F09%2F05%2F%E5%86%8D%E8%B0%88%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[我把书籍PDF版本和配套代码放在我的百度云里，附上链接地址：百度云链接：https://pan.baidu.com/s/1dp9K-KljcZoctUL37yCvWg 密码：43po小亮的同学（栗同学）在大学和小亮是一个专业的，研究生申请到了法国格勒诺布尔大学，（很优秀哈）。先介绍一下这个大学哈：格勒诺布尔大学集团（格勒诺布尔-阿尔卑斯大学）是一所拥有近七百年历史的国立研究型大学，其科研实力处于法国顶尖水平，诞生过两位诺贝尔奖获得者（克劳斯·冯·克利青Klaus von Klitzing，路易·奈尔Louis Néel），一位图灵奖获得者（Joseph Sifakis），同时也是联合国教科文组织国际传播学教席（Chaire UNESCO）所在处。院校声誉：具有世界影响力的法国顶尖大学优势专业：自然科学、医学、社会与人文科学、语言学、信息传播学中国教育部是否认证：获得认证全球排名：CWUR（2018）世界大学排名第97位 USNews世界大学排名 （2018）全球大学排名第146位ARWU （2017）世界大学学术排名第152位THE（2018）泰晤士高等教育世界大学排名第301-350位QS（2018）世界大学排名第236位韦伯麦特里克斯网(Webometrics)世界大学（2018）排名第295名下面是这个学校的校园，是不是很美呐！！！好啦，言归正传！下面介绍：数据结构PDF与配套代码-C语言-严蔚敏小亮将大学上数据结构（C语言）这门课的课件和实验也单独整理出来了，放在一个文件夹中（数据结构PPT），分享给大家！（如果大家觉得不和胃口，可以忽略这个文件夹，直接跳转到下面的文件夹哈。）然后是《数据结构(C语言版).严蔚敏_吴伟民》扫描版PDF和本书的配套代码，如下图所示:一点点感受：其实，数据结构小亮觉得非常重要，他强调逻辑的严密性和算法的高效性。最近小亮的师兄也在找工作——&gt;机器学习方向算法岗，亲身感受到了算法基础的重要性，而算法又不是短期内能够提升的，贵在平时的积累与代码实践，所以小亮特意整理了这些资料，分享给技术小伙伴们！]]></content>
      <categories>
        <category>数据结构 C语言 算法</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汉字拼音转换工具_Python版]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F09%2F03%2F%E6%B1%89%E5%AD%97%E6%8B%BC%E9%9F%B3%E8%BD%AC%E6%8D%A2%E5%B7%A5%E5%85%B7-Python%E7%89%88%2F</url>
    <content type="text"><![CDATA[环境配置：Wn10+CPU i7-6700Pycharm 2018python 3.6numpy 1.14.5一、github介绍先附上github的一张图片哈：github地址如下：https://github.com/mozillazg/python-pinyin二、特性(1) 根据词组智能匹配最正确的拼音。(2) 支持多音字。(3) 简单的繁体支持, 注音支持。(4) 支持多种不同拼音/注音风格。三、安装注意：以下两种安装方式选择其一即可1、pip安装1$ pip install pypinyin 2、pycharm安装四、代码实践123456789101112131415161718192021222324#coding:utf-8from pypinyin import pinyin, lazy_pinyin, Stylevalue1 = pinyin('天津大学')print(value1)value2 = pinyin('天津大学', heteronym=True) # 启用多音字模式print(value2)value3 = pinyin('天津大学', style=Style.FIRST_LETTER) # 设置拼音风格print(value3)value4 = pinyin('天津大学', style=Style.TONE2, heteronym=True)print(value4)value5 = pinyin('天津大学', style=Style.BOPOMOFO) # 注音风格print(value5)value6 = pinyin('天津大学', style=Style.CYRILLIC) # 俄语字母风格print(value6)value7 = lazy_pinyin('天津大学') # 不考虑多音字的情况print(value7) 五、实验结果1234567[[&apos;tiān&apos;], [&apos;jīn&apos;], [&apos;dà&apos;], [&apos;xué&apos;]][[&apos;tiān&apos;], [&apos;jīn&apos;], [&apos;dà&apos;], [&apos;xué&apos;]][[&apos;t&apos;], [&apos;j&apos;], [&apos;d&apos;], [&apos;x&apos;]][[&apos;tia1n&apos;], [&apos;ji1n&apos;], [&apos;da4&apos;], [&apos;xue2&apos;]][[&apos;ㄊㄧㄢ&apos;], [&apos;ㄐㄧㄣ&apos;], [&apos;ㄉㄚˋ&apos;], [&apos;ㄒㄩㄝˊ&apos;]][[&apos;тянь1&apos;], [&apos;цзинь1&apos;], [&apos;да4&apos;], [&apos;сюэ2&apos;]][&apos;tian&apos;, &apos;jin&apos;, &apos;da&apos;, &apos;xue&apos;]]]></content>
      <categories>
        <category>Python NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018算法工程师秋招集锦]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F09%2F03%2F2018%E7%AE%97%E6%B3%95%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%A7%8B%E6%8B%9B%E9%9B%86%E9%94%A6%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Learning Pyspark]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F08%2F25%2FLearning-Pyspark%2F</url>
    <content type="text"><![CDATA[我把书籍PDF版本和配套代码放在我的百度云里，附上链接地址：百度云链接：https://pan.baidu.com/s/1EogSZ3mT4tAYZyqj6WprIg 密码：vsmv下面介绍一下这本书：Learning Pyspark 感谢您选择本书开始您的PySpark冒险，我希望您像我一样兴奋。当DennyLee第一次告诉我这本新书的时候很高兴 - 使Apache Spark成为最重要的事情之一精彩的平台，支持Java / Scala / JVM世界和Python（以及最近的R）世界。许多以前针对Spark的书都是专注于所有核心语言，或主要关注JVM语言，所以很高兴看到PySpark有机会用这样的专用书来发光经验丰富的Spark教育家。通过支持这两个不同的世界，我们是能够更有效地作为数据科学家和数据工程师一起工作窃取彼此社区的最佳想法。能够有机会审查其早期版本是一种荣幸这本书，只是增加了我对这个项目的兴奋。我有这个特权参加一些相同的会议和聚会，并观看作者向各种受众介绍Spark世界的新概念（从第一部分开始）定时器到老手），他们做了很好的工作，提炼他们的经验这本书。作者的经验从他们的作品中汲取了一切对所涉及主题的解释。除了简单介绍PySpark之外，他们还有还花时间查看来自社区的新闻包，例如GraphFrames和TensorFrames。我认为社区是决定时经常被忽视的组件之一使用什么工具，Python有一个很棒的社区，我很期待您加入了PythonSpark社区。所以，享受你的冒险;我知道你是与Denny Lee和TomekDrabas保持良好关系。我真的相信这一点一个多样化的Spark用户社区，我们将能够制作更好的工具。大家好，所以我希望能在一次会议，聚会或邮寄中见到你很快列出:)霍尔顿卡劳附：我欠丹尼一杯啤酒;如果你想给我买一个Bud Light lime（或lime-a-rita）我非常感激（虽然他可能不像我那样有趣）.本书作者：Tomasz DrabasTomasz Drabas是一名为微软工作的数据科学家，目前居住在微软西雅图地区。 他在数据分析和数据科学方面拥有超过13年的经验在众多的领域：先进技术，航空公司，电信，金融，他在三大洲工作时获得了咨询：欧洲，澳大利亚，和北美。 在澳大利亚期间，Tomasz一直在攻读他的博士学位运营研究，重点关注选择建模和收益管理航空业的应用。]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python之禅]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F08%2F24%2FPython%E4%B9%8B%E7%A6%85%2F</url>
    <content type="text"><![CDATA[The Zen of Python, by Tim PetersBeautiful is better than ugly.Explicit is better than implicit.Simple is better than complex.Complex is better than complicated.Flat is better than nested.Sparse is better than dense.Readability counts.Special cases aren’t special enough to break the rules.Although practicality beats purity.Errors should never pass silently.Unless explicitly silenced.In the face of ambiguity, refuse the temptation to guess.There should be one– and preferably only one –obvious way to do it.Although that way may not be obvious at first unless you’re Dutch.Now is better than never.Although never is often better than right now.If the implementation is hard to explain, it’s a bad idea.If the implementation is easy to explain, it may be a good idea.Namespaces are one honking great idea – let’s do more of those! Tim Peters的Python之禅美丽胜过丑陋。显式优于隐式。简单比复杂更好。复杂比复杂更好。Flat优于嵌套。稀疏优于密集。可读性很重要。特殊情况不足以打破规则。虽然实用性胜过纯洁。错误不应该默默地传递。除非明确沉默。面对模棱两可，拒绝猜测的诱惑。应该有一个 - 最好只有一个 - 显而易见的方法。虽然这种方式起初可能并不明显，除非你是荷兰人。现在总比没有好。虽然现在永远不会比*正确好。如果实施很难解释，那是个坏主意。如果实现很容易解释，那可能是个好主意。命名空间是一个很棒的主意 - 让我们做更多的事情吧！]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GAN的理解与TensorFlow的实现]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F08%2F24%2FGAN%E7%9A%84%E7%90%86%E8%A7%A3%E4%B8%8ETensorFlow%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[笔者信息：Next_Legend QQ:1219154092 人工智能 自然语言处理 图像处理 神经网络 高维信息处理 ——2018.7.31于天津大学一、前言本文会从头介绍生成对抗式网络的一些内容，从生成式模型开始说起，到GAN的基本原理，InfoGAN，AC-GAN的基本科普，如果有任何有错误的地方，请随时喷，我刚开始研究GAN这块的内容，希望和大家一起学习。二、生成式模型何为生成式模型？在很多machine learning的教程或者公开课上，通常会把machine learning的算法分为两类： 生成式模型、判别式模型；其区别在于： 对于输入x，类别标签y，在生成式模型中估计其联合概率分布，而判别式模型估计其属于某类的条件概率分布。 常见的判别式模型包括：LogisticRegression， SVM, Neural Network等等，生成式模型包括：Naive Bayes， GMM， Bayesian Network， MRF 等等。三、研究生成式模型的意义生成式模型的特性主要包括以下几个方面： 在应用数学和工程方面，生成式模型能够有效地表征高维数据分布； 生成式模型能够作为一种技术手段辅助强化学习，能够有效表征强化学习模型中的state状态(这里不扩展，后面会跟RL的学习笔记)； 对semi-supervised learning也有比较好的效果，能够在miss data下训练模型，并在miss data下给出相应地输出； 在对于一个输入伴随多个输出的场景下，生成式模型也能够有效工作，而传统的机器学习方法通过最小化模型输出和期望输出的某个object function的值 无法训练单输入多输出的模型，而生成式模型，尤其是GAN能够hold住这种场景，一个典型的应用是通过场景预测video的下一帧。生成式模型一些典型的应用： 图像的超分辨率 iGAN：Generative Visual Manipulation on the Natural Image Manifold 图像转换四、生成式模型族谱上图涵盖了基本的生成式模型的方法，主要按是否需要定义概率密度函数分为：Explicit density modelsexplicit density models 又分为tractable explicit models和逼近的explicit model，怎么理解呢，tractable explicit model通常可以直接通过数学方法来建模求解，而基于逼近的explicit model通常无法直接对数据分布进行建模，可以利用数学里的一些近似方法来做数据建模， 通常基于逼近的explicit model分为确定性（变分方法：如VAE的lower bound）和随机性的方法（马尔科夫链蒙特卡洛方法）。 VAE lower bound： 马尔科夫链蒙特卡洛方法（MCMC），一种经典的基于马尔科夫链的抽样方法，通过多次来拟合分布。比较好的教程：A Beginner’s Guide to Monte Carlo Markov Chain MCMC Analysis, An Introduction to MCMC for Machine Learning.Implicit density models无需定义明确的概率密度函数，代表方法包括马尔科夫链、生成对抗式网络（GAN），该系列方法无需定义数据分布的描述函数。 五、生成对抗式网络与其他生成式网络对比生成对抗式网络（GAN）能够有效地解决很多生成式方法的缺点，主要包括： 并行产生samples； 生成式函数的限制少，如无需合适马尔科夫采样的数据分布（Boltzmann machines），生成式函数无需可逆、latent code需与sample同维度（nonlinear ICA）； 无需马尔科夫链的方法（Boltzmann machines， GSNs）； 相对于VAE的方法，无需variational bound；GAN比其他方法一般来说性能更好。 可以使用冒号来定义对齐方式： 六、GAN工作原理GAN主要由两部分构成：generator和discriminator，generator主要是从训练数据中产生相同分布的samples，而discriminator 则是判断输入是真实数据还是generator生成的数据，discriminator采用传统的监督学习的方法。这里我们可以这样类比，generator 是一个伪造假币的专业人士，discriminator是警察，generator的目的是制造出尽可能以假乱真的假钞，而discriminator是为了能 鉴别是否为假钞，最终整个gan会达到所谓的纳什均衡，Goodfellow在他的paperGAN的理解与TF的实现-小石头的码疯窝中有严格的数学证明，当$p_G$==$p_{data}$时达到 全局最优：另一个比较明显看得懂的图如下：图中黑色点线为真实数据分布$p_{data}$，绿色线为generator生成的数据分布$p_{G}$,而Discriminator就是蓝色点线，其目的是为了将$p_{data}$和$p_{G}$ 区分，(a)中是初始状态，然后会更新Discriminator中的参数，若干次step之后，Discriminator有了较大的判断力即到了(b)的状态，之后会更新G的模型使其生成的数据分布（绿色线）更加趋近与真实数据分布， 若干次G和D的模型参数更新后，理论上最终会达到(d)的状态即G能够产生和真实数据完全一致的分布(证明见上一张图)，如从随机数据分布生成人脸像。七、如何训练GAN因为GAN结构的不同，和常规训练一个dl model方法不同， 这里采用simultaneous SGD，每一个step中，会有两个两个梯度优化的 过程，一个是更新discriminator的参数来最小化$J_{(D)}$，一个是更新generator的参数来最小$J_{(G)}$，通常会选用Adam来作为最优化的优化器， 也有人建议可以不等次数地更新generator和discriminator（有相关工作提出，1：1的在实际中更有效：Adam: A Method for Stochastic Optimization） 如何训练GAN，在Goodfellow的GAN的tutorial还有一些代码中有更多的描述包括不同的cost function， 这里我就不详细展开了。1、DCGANGAN出来后很多相关的应用和方法都是基于DCGAN的结构，DCGAN即”Deep Convolution GAN”，通常会有一些约定俗成的规则： 在Discriminator和generator中大部分层都使用batch normalization，而在最后一层时通常不会使用batch normalizaiton，目的 是为了保证模型能够学习到数据的正确的均值和方差； 因为会从random的分布生成图像，所以一般做需要增大图像的空间维度时如77-&gt;1414， 一般会使用strdie为2的deconv（transposed convolution）； 通常在DCGAN中会使用Adam优化算法而不是SGD。2、各种GAN这里有个大神把各种gan的paper都做了一个统计AdversarialNetsPapers这里大家有更多的兴趣可以直接去看对应的paper，我接下来会尽我所能描述下infogan和AC-GAN这两块的内容3、InfoGANInfoGAN是一种能够学习disentangled representation的GAN，何为disentangled representation？比如人脸数据集中有各种不同的属性特点，如脸部表情、是否带眼睛、头发的风格眼珠的颜色等等，这些很明显的相关表示， InfoGAN能够在完全无监督信息（是否带眼睛等等）下能够学习出这些disentangled representation，而相对于传统的GAN，只需修改loss来最大化GAN的input的noise（部分fixed的子集）和最终输出之间的互信息。4、原理为了达到上面提到的效果，InfoGAN必须在input的noise来做一些文章，将noise vector划分为两部分： z: 和原始的GAN input作用一致； c: latent code，能够在之后表示数据分布中的disentangled representation那么如何从latent code中学到相应的disentangled representation呢？ 在原始的GAN中，忽略了c这部分的影响，即GAN产生的数据分布满足$P_{G}(x|C)=P(x)$,为了保证能够利用c这部分信息， 作者提出这样一个假设：c与generator的输出相关程度应该很大，而在信息论中，两个数据分布的相关程度即互信息， 即generator的输出和input的c的$I(c;G(z,c))$应该会大。 所以，InfoGAN就变成如下的优化问题：因为互信息的计算需要后验概率的分布（下图红线部分），在实际中很难直接使用，因此，在实际训练中一般不会直接最大化$I(c;G(z,c))$这里作者采用和VAE类似的方法，增加一个辅助的数据分布为后验概率的low bound： 所以，这里互信息的计算如下：这里相关的证明就不深入了，有兴趣的可以去看看paper。5、实验我写的一版基于TensorFlow的Info-GAN实现：Info-GANburness/tensorflow-101 random的label信息，和对应生成的图像：不同random变量控制产生同一class下的不同输出：6、AC-GANAC-GAN即auxiliary classifier GAN，对应的paper：[1610.09585] Conditional Image Synthesis With Auxiliary Classifier GANs, 如前面的示意图中所示，AC-GAN的Discriminator中会输出相应的class label的概率，然后更改loss fuction，增加class预测正确的概率， ac-gan是一个tensorflow相关的实现，基于作者自己开发的sugartensor，感觉和paper里面在loss函数的定义上差异，看源码的时候注意下，我这里有参考写了一个基于原生tensorflow的版本AC-GAN.实验各位有兴趣的可以拿代码在其他的数据集上也跑一跑，AC-GAN能够有效利用class label的信息，不仅可以在G时指定需要生成的image的label，同事该class label也能在Discriminator用来扩展loss函数，增加整个对抗网络的性能。 random的label信息，和对应生成的图像：不同random变量控制产生同一class下的不同输出：七、总结照例总结一下，本文中，我基本介绍了下生成式模型方法的各个族系派别，到GAN的基本内容，到InfoGAN、AC-GAN，大部分的工作都来自于阅读相关的paper，自己相关的工作就是 tensorflow下参考sugartensor的内容重现了InfoGAN、AC-GAN的相关内容。当然，本人菜鸟一枚，难免有很多理解不到位的地方，写出来更多的是作为分享，让更多人了解GAN这块的内容，如果任何错误或不合适的地方，敬请在评论中指出，我们一起讨论一起学习 另外我的所有相关的代码都在github上:GAN,相信读一下无论是对TensorFlow的理解还是GAN的理解都会 有一些帮助，简单地参考mnist.py修改下可以很快的应用到你的数据集上，如果有小伙伴在其他数据集上做出有意思的实验效果的，欢迎分享。 原文地址： http://www.leiphone.com/news/201702/GZsIbIb9V9AUGmb6.html]]></content>
      <categories>
        <category>Tensorflow实战深度学习</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于深度学习tensorflow实现文本分类任务的注意力机制]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F08%2F24%2FTensorflow%E5%AE%9E%E7%8E%B0%E5%9F%BA%E4%BA%8ERNN%E7%9A%84%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[要点：该教程为深度学习tensorflow实现文本分类任务的注意力机制，实现可视化注意力文本。环境配置：Wn10+CPU i7-6700Pycharm2018Tensorflow 1.8.0Tensorboard 1.8.0笔者信息：Next_Legend QQ:1219154092 人工智能 自然语言处理 图像处理 神经网络 ——2018.8.8于天津大学 一、下载代码 该代码见笔者的资源下载部分https://download.csdn.net/download/jinyuan7708/10592063 代码不需要改动，只需要配置好环境和安装好相应的库，就可以训练和测试了。二、相应的库文件 tensorflow 1.8.0 tensorboard 1.8.0 numpy keras tqdm三、工程目录文件 该项目主要包括attention.py train.py utils.py visualize.py四个文件夹 其中train.py文件是训练模型的文件，运行后会生成model.data-00000-of-00001、model.index、model.meta以及checkpoint文件，也就是训练生成的模型文件。四、核心代码train.py文件代码 from __future__ import print_function, division import numpy as np import tensorflow as tf from keras.datasets import imdb from tensorflow.contrib.rnn import GRUCell from tensorflow.python.ops.rnn import bidirectional_dynamic_rnn as bi_rnn from tqdm import tqdm from attention import attention from utils import get_vocabulary_size, fit_in_vocabulary, zero_pad, batch_generator NUM_WORDS = 10000 INDEX_FROM = 3 SEQUENCE_LENGTH = 250 EMBEDDING_DIM = 100 HIDDEN_SIZE = 150 ATTENTION_SIZE = 50 KEEP_PROB = 0.8 BATCH_SIZE = 256 NUM_EPOCHS = 3 # Model easily overfits without pre-trained words embeddings, that&apos;s why train for a few epochs DELTA = 0.5 MODEL_PATH = &apos;./model&apos; # Load the data set (X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=NUM_WORDS, index_from=INDEX_FROM) # Sequences pre-processing vocabulary_size = get_vocabulary_size(X_train) X_test = fit_in_vocabulary(X_test, vocabulary_size) X_train = zero_pad(X_train, SEQUENCE_LENGTH) X_test = zero_pad(X_test, SEQUENCE_LENGTH) # Different placeholders with tf.name_scope(&apos;Inputs&apos;): batch_ph = tf.placeholder(tf.int32, [None, SEQUENCE_LENGTH], name=&apos;batch_ph&apos;) target_ph = tf.placeholder(tf.float32, [None], name=&apos;target_ph&apos;) seq_len_ph = tf.placeholder(tf.int32, [None], name=&apos;seq_len_ph&apos;) keep_prob_ph = tf.placeholder(tf.float32, name=&apos;keep_prob_ph&apos;) # Embedding layer with tf.name_scope(&apos;Embedding_layer&apos;): embeddings_var = tf.Variable(tf.random_uniform([vocabulary_size, EMBEDDING_DIM], -1.0, 1.0), trainable=True) tf.summary.histogram(&apos;embeddings_var&apos;, embeddings_var) batch_embedded = tf.nn.embedding_lookup(embeddings_var, batch_ph) # (Bi-)RNN layer(-s) rnn_outputs, _ = bi_rnn(GRUCell(HIDDEN_SIZE), GRUCell(HIDDEN_SIZE), inputs=batch_embedded, sequence_length=seq_len_ph, dtype=tf.float32) tf.summary.histogram(&apos;RNN_outputs&apos;, rnn_outputs) # Attention layer with tf.name_scope(&apos;Attention_layer&apos;): attention_output, alphas = attention(rnn_outputs, ATTENTION_SIZE, return_alphas=True) tf.summary.histogram(&apos;alphas&apos;, alphas) # Dropout drop = tf.nn.dropout(attention_output, keep_prob_ph) # Fully connected layer with tf.name_scope(&apos;Fully_connected_layer&apos;): W = tf.Variable(tf.truncated_normal([HIDDEN_SIZE * 2, 1], stddev=0.1)) # Hidden size is multiplied by 2 for Bi-RNN b = tf.Variable(tf.constant(0., shape=[1])) y_hat = tf.nn.xw_plus_b(drop, W, b) y_hat = tf.squeeze(y_hat) tf.summary.histogram(&apos;W&apos;, W) with tf.name_scope(&apos;Metrics&apos;): # Cross-entropy loss and optimizer initialization loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y_hat, labels=target_ph)) tf.summary.scalar(&apos;loss&apos;, loss) optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss) # Accuracy metric accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.round(tf.sigmoid(y_hat)), target_ph), tf.float32)) tf.summary.scalar(&apos;accuracy&apos;, accuracy) merged = tf.summary.merge_all() train_batch_generator = batch_generator(X_train, y_train, BATCH_SIZE) test_batch_generator = batch_generator(X_test, y_test, BATCH_SIZE) train_writer = tf.summary.FileWriter(&apos;./logdir/train&apos;, accuracy.graph) test_writer = tf.summary.FileWriter(&apos;./logdir/test&apos;, accuracy.graph) session_conf = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True)) saver = tf.train.Saver() if __name__ == &quot;__main__&quot;: with tf.Session(config=session_conf) as sess: sess.run(tf.global_variables_initializer()) print(&quot;Start learning...&quot;) for epoch in range(NUM_EPOCHS): loss_train = 0 loss_test = 0 accuracy_train = 0 accuracy_test = 0 print(&quot;epoch: {}\t&quot;.format(epoch), end=&quot;&quot;) # Training num_batches = X_train.shape[0] // BATCH_SIZE for b in tqdm(range(num_batches)): x_batch, y_batch = next(train_batch_generator) seq_len = np.array([list(x).index(0) + 1 for x in x_batch]) # actual lengths of sequences loss_tr, acc, _, summary = sess.run([loss, accuracy, optimizer, merged], feed_dict={batch_ph: x_batch, target_ph: y_batch, seq_len_ph: seq_len, keep_prob_ph: KEEP_PROB}) accuracy_train += acc loss_train = loss_tr * DELTA + loss_train * (1 - DELTA) train_writer.add_summary(summary, b + num_batches * epoch) accuracy_train /= num_batches # Testing num_batches = X_test.shape[0] // BATCH_SIZE for b in tqdm(range(num_batches)): x_batch, y_batch = next(test_batch_generator) seq_len = np.array([list(x).index(0) + 1 for x in x_batch]) # actual lengths of sequences loss_test_batch, acc, summary = sess.run([loss, accuracy, merged], feed_dict={batch_ph: x_batch, target_ph: y_batch, seq_len_ph: seq_len, keep_prob_ph: 1.0}) accuracy_test += acc loss_test += loss_test_batch test_writer.add_summary(summary, b + num_batches * epoch) accuracy_test /= num_batches loss_test /= num_batches print(&quot;loss: {:.3f}, val_loss: {:.3f}, acc: {:.3f}, val_acc: {:.3f}&quot;.format( loss_train, loss_test, accuracy_train, accuracy_test )) train_writer.close() test_writer.close() saver.save(sess, MODEL_PATH) print(&quot;Run &apos;tensorboard --logdir=./logdir&apos; to checkout tensorboard logs.&quot;) 五、训练过程 笔者由于使用的 CPU来进行训练，所以速度比较慢，感兴趣的朋友可以考虑使用GPU来计算，可以大大减少训练模型的时间。如果不会搭建gpu环境的小伙伴可以参考我的另一篇Tensorflow gpu环境搭建 ，附上地址哈： https://blog.csdn.net/jinyuan7708/article/details/79642924六、训练结果 七、Tensorboard可视化八、visualization可视化结果得到模型后，再继续执行visualize.py文件，生成结果可视化。如下图：至此，我们的教程就结束啦，代码等文件我上传到我的blog下载资源部分，欢迎大家下载批评指正哈!代码地址：https://download.csdn.net/download/jinyuan7708/10592063]]></content>
      <categories>
        <category>Tensorflow实战深度学习</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中英文NLP集成型工具汇总]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F08%2F24%2F%E4%B8%AD%E8%8B%B1%E6%96%87NLP%E9%9B%86%E6%88%90%E5%9E%8B%E5%B7%A5%E5%85%B7%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[该文档简单总结了一下集成的中英文NLP工具，分享给NLP领域的大家！笔者信息：Next_Legend QQ:1219154092 机器学习 自然语言处理 计算机视觉 深度学习——2018.8.19于天津大学 1、面向研究的StanfordNLP(Java) (CoreNLP/Parder/POS Tager/NER…) 网页链接2、面向应用的SpaCy(Python) 网页链接3、哈工大语言技术平台LTP(C++) 网页链接4、本土的HanLP(Java) 网页链接5、轻量非主流的xmnlp(Python) 网页链接6、相对零散的THUNLP开放项目 网页链接7、复旦大学NLP 网页链接8、清华大学NLP 网页链接9、TEXTBLOG 网页链接10、PyNLPIR 网页链接11、Polyglot 网页链接12、NLTK 网页链接其他的NLP工具小编暂时没有了解，欢迎有使用经验的同学朋友补充！]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法_NLP_深度学习_机器学习面试笔记]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F08%2F24%2F%E7%AE%97%E6%B3%95_NLP_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[笔者信息：Next_Legend QQ:1219154092 机器学习 自然语言处理 图像处理 深度学习——2018.8.13于天津大学 GitHub 地址：https://github.com/imhuay/CS_Interview_Notes-Chinese深度学习/机器学习面试问题整理，想法来源于这个仓库. - 该仓库整理了“花书”《深度学习》中的一些常见问题，其中部分偏理论的问题没有收录，如有需要可以浏览原仓库。此外，还包括我看到的所有机器学习/深度学习面经中的问题。除了其中 DL/ML 相关的，其他与算法岗相关的计算机知识也会记录。但是不会包括如前端/测试/JAVA/Android等岗位中有关的问题。RoadMap数学 微积分的本质深度学习的核心自然语言处理 词向量 Word2VecGloVeFastTextWordRank TODO序列建模 TODO工具库机器学习-深度学习 公共基础 背景知识损失函数深度学习 深度学习基础《深度学习》整理CNN专题机器学习 机器学习算法机器学习实践算法 题解-剑指Offer编程语言 Cpp专题-基础知识Cpp专题-左值与右值笔试面经项目经验code 工具库 gensim.FastText 的使用倒排索引Tensorflow 基础 TODO各公司招聘要求必备清单 TODO深度学习 反向传播算法梯度下降法深度学习实践（项目经验）相关代码 TODO机器学习算法 逻辑斯蒂回归支持向量机AdaBoost 算法GBDT 梯度提升决策树相关代码 TODO计算机基础 必背算法Python 常识 TODOC++ 常识 TODO欢迎分享你在深度学习/机器学习面试过程中遇见的问题！你可以直接以你遇到的问题作为 issue 标题，然后分享你的回答或者其他参考资料。当然，你也可以直接创建 PR，分享问题的同时改正我的错误！ 我会经常修改文档的结构（特别是代码的链接）。如果文中有链接失效，请告诉我！ 文档中大部分链接都是指向仓库内的文件或标记；涉及编程代码的链接会指向我的另一个仓库（Algorithm_for_Interview）Referenceexacity/deeplearningbook-chinese: 深度学习中文版 elviswf/DeepLearningBookQA_cn: 深度学习面试问题 回答对应的DeepLearning中文版页码huihut/interview: C/C++面试知识总结 七月在线：结构之法 算法之道 - CSDN博客在线 LaTeX 公式编辑器 http://www.codecogs.com/latex/eqneditor.phpGitHub 搜索：Deep Learning InterviewGitHub 搜索：Machine Learning Interview geekcircle/machine-learning-interview-qa: 人工智能-机器学习笔试面试题解析 牛客网-讨论区]]></content>
      <categories>
        <category>面试集锦</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于python+opencv的图像目标区域自动提取]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F08%2F24%2F%E5%9F%BA%E4%BA%8Epython%2Bopencv%E7%9A%84%E5%9B%BE%E5%83%8F%E7%9B%AE%E6%A0%87%E5%8C%BA%E5%9F%9F%E8%87%AA%E5%8A%A8%E6%8F%90%E5%8F%96%EF%BC%88%E6%9C%AC%E9%A1%B9%E7%9B%AE%E4%B8%BA%E6%8F%90%E5%8F%96%E7%BA%B8%E5%BC%A0%E4%B8%AD%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%89%2F</url>
    <content type="text"><![CDATA[要点：该教程为基于python+opencv的图像目标区域自动提取，实现自动提取一张照片中的纸张内容环境配置：Wn10+CPU i7-6700Pycharm2018opencv-python 3.4.2.17numpy 1.14.5笔者信息：Next_Legend QQ:1219154092 人工智能 自然语言处理 图像处理 神经网络 ——2018.8.12于天津大学 该项目的代码在笔者的资源仓库中，代码地址：基于python+opencv的图像目标区域自动提取 一、项目背景一张照片中的感兴趣区域总是沿着x,y,z三个轴都有一定倾斜（如下图），要想把照片翻转到平行位置，需要进行透视变换，而透视变换需要同一像素点变换前后的坐标。由此可以想到，提取矩形区域四个角的坐标作为变换前的坐标，变换后的坐标可以设为照片的四个角落，经过投影变换，矩形区域将会翻转并充满图像。因此我们要解决的问题变为：提取矩形的四个角落、进行透视变换。 二、提取矩形角落坐标矩形的检测主要是提取边缘，图片显示部分的亮度通常高于周围环境，我们可以将图片阈值化，将图片部分与周围环境明显的分别开来，这对后边的边缘检测非常有帮助。检测矩形并提取坐标需要对图像进行预处理、边缘检测、提取轮廓、检测凸包、角点检测。1、预处理转为灰度图由于手机拍摄的照片像素可能会很高，为了加快处理速度，我们首先将图像转化为灰度图1234image = cv2.imread(Config.src)gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)srcWidth, srcHeight, channels = image.shapeprint(srcWidth, srcHeight) 2、中值滤波 1binary = cv2.medianBlur(gray,7) 3、转化为二值图像12ret, binary = cv2.threshold(binary, Config.threshold_thresh, 255, cv2.THRESH_BINARY)cv2.imwrite("1-threshold.png", binary, [int(cv2.IMWRITE_PNG_COMPRESSION), 9]) 此时图片已经变成了这个样子：可见纸张页面部分已经与背景环境分离开来。4、边缘检测与轮廓处理我们用Canny算子边缘检测，提取轮廓 123# canny提取轮廓binary = cv2.Canny(binary, 0, 60, apertureSize = 3)cv2.imwrite("3-canny.png", binary, [int(cv2.IMWRITE_PNG_COMPRESSION), 9]) 提取轮廓后，拟合外接多边形（矩形） 123# 提取轮廓后，拟合外接多边形（矩形）_,contours,_ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)print("len(contours)=%d"%(len(contours))) 5、提取面积最大的轮廓并用多边形将轮廓包围 123456789101112131415161718192021222324252627282930313233343536373839404142for idx,c in enumerate(contours): if len(c) &lt; Config.min_contours: continue epsilon = Config.epsilon_start while True: approx = cv2.approxPolyDP(c,epsilon,True) print("idx,epsilon,len(approx),len(c)=%d,%d,%d,%d"%(idx,epsilon,len(approx),len(c))) if (len(approx) &lt; 4): break if math.fabs(cv2.contourArea(approx)) &gt; Config.min_area: if (len(approx) &gt; 4): epsilon += Config.epsilon_step print("epsilon=%d, count=%d"%(epsilon,len(approx))) continue else: #for p in approx: # cv2.circle(binary,(p[0][0],p[0][1]),8,(255,255,0),thickness=-1) approx = approx.reshape((4, 2)) # 点重排序, [top-left, top-right, bottom-right, bottom-left] src_rect = order_points(approx) cv2.drawContours(image, c, -1, (0,255,255),1) cv2.line(image, (src_rect[0][0],src_rect[0][1]),(src_rect[1][0],src_rect[1][1]),color=(100,255,100)) cv2.line(image, (src_rect[2][0],src_rect[2][1]),(src_rect[1][0],src_rect[1][1]),color=(100,255,100)) cv2.line(image, (src_rect[2][0],src_rect[2][1]),(src_rect[3][0],src_rect[3][1]),color=(100,255,100)) cv2.line(image, (src_rect[0][0],src_rect[0][1]),(src_rect[3][0],src_rect[3][1]),color=(100,255,100)) # 获取最小矩形包络 rect = cv2.minAreaRect(approx) # rect = cv2.maxAreaRect(approx) box = cv2.boxPoints(rect) box = np.int0(box) box = box.reshape(4,2) box = order_points(box) print("approx-&gt;box") print(approx) print(src_rect) print(box) w,h = point_distance(box[0],box[1]), \ point_distance(box[1],box[2]) print("w,h=%d,%d"%(w,h)) 6、 透视变换 12345678910dst_rect = np.array([ [0, 0], [w - 1, 0], [w - 1, h - 1], [0, h - 1]], dtype="float32") M = cv2.getPerspectiveTransform(src_rect, dst_rect) warped = cv2.warpPerspective(image, M, (w, h)) cv2.imwrite("transfer%d.png"%idx, warped, [int(cv2.IMWRITE_PNG_COMPRESSION), 9]) break 总结本项目利用了照片背景亮度较高的特点，通过二值化突出轮廓提取坐标，进行透视变换。但是局限性在于，如果矩形的亮度与背景相差不大，就很难用这种方法检测到轮廓还需要算法优化。该项目的代码在笔者的资源仓库中，代码地址：基于python+opencv的图像目标区域自动提取]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[基于Kears的Attention实战]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F08%2F24%2F%E5%9F%BA%E4%BA%8EKeras%E7%9A%84attention%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[要点：该教程为基于Kears的Attention实战，环境配置：Wn10+CPU i7-6700Pycharm 2018python 3.6numpy 1.14.5Keras 2.0.2Matplotlib 2.2.2强调：各种库的版本型号一定要配置对，因为Keras以及Tensorflow升级更新比较频繁，很多函数更新后要么更换了名字，要么没有这个函数了，所以大家务必重视。相关代码我放在了我的代码仓库里哈，欢迎大家下载，这里附上地址：基于Kears的Attention实战笔者信息：Next_Legend QQ:1219154092 人工智能 自然语言处理 图像处理 神经网络——2018.8.21于天津大学 一、导读最近两年，尤其在今年，注意力机制(Attention)及其变种Attention逐渐热了起来，在很多顶会Paper中都或多或少的用到了attention,所以小编出于好奇，整理了这篇基于Kears的Attention实战，本教程仅从代码的角度来看Attention。通过一个简单的例子，探索Attention机制是如何在模型中起到特征选择作用的。二、代码实战（一）1、导入相关库文件1234567import numpy as npfrom attention_utils import get_activations, get_datanp.random.seed(1337) # for reproducibilityfrom keras.models import *from keras.layers import Input, Dense, mergeimport tensorflow as tf 2、数据生成函数 1234567891011121314def get_data(n, input_dim, attention_column=1): """ Data generation. x is purely random except that it's first value equals the target y. In practice, the network should learn that the target = x[attention_column]. Therefore, most of its attention should be focused on the value addressed by attention_column. :param n: the number of samples to retrieve. :param input_dim: the number of dimensions of each element in the series. :param attention_column: the column linked to the target. Everything else is purely random. :return: x: model inputs, y: model targets """ x = np.random.standard_normal(size=(n, input_dim)) y = np.random.randint(low=0, high=2, size=(n, 1)) x[:, attention_column] = y[:, 0] return x, y 3、模型定义函数将输入进行一次变换后，计算出Attention权重，将输入乘上Attention权重，获得新的特征。123456789101112def build_model(): inputs = Input(shape=(input_dim,)) # ATTENTION PART STARTS HERE attention_probs = Dense(input_dim, activation='softmax', name='attention_vec')(inputs) attention_mul =merge([inputs, attention_probs], output_shape=32, name='attention_mul', mode='mul') # ATTENTION PART FINISHES HERE attention_mul = Dense(64)(attention_mul) output = Dense(1, activation='sigmoid')(attention_mul) model = Model(input=[inputs], output=output) return model 4、主函数12345678910111213141516171819202122232425262728if __name__ == '__main__': N = 10000 inputs_1, outputs = get_data(N, input_dim) m = build_model() m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) print(m.summary()) m.fit([inputs_1], outputs, epochs=20, batch_size=64, validation_split=0.5) testing_inputs_1, testing_outputs = get_data(1, input_dim) # Attention vector corresponds to the second matrix. # The first one is the Inputs output. attention_vector = get_activations(m, testing_inputs_1, print_shape_only=True, layer_name='attention_vec')[0].flatten() print('attention =', attention_vector) # plot part. import matplotlib.pyplot as plt import pandas as pd pd.DataFrame(attention_vector, columns=['attention (%)']).plot(kind='bar', title='Attention Mechanism as ' 'a function of input' ' dimensions.') plt.show() 5、运行结果代码中，attention_column为1，也就是说，label只与数据的第1个特征相关。从运行结果中可以看出，Attention权重成功地获取了这个信息。 三、代码实战（二）1、导入相关库文件1234567891011from keras.layers import mergefrom keras.layers.core import *from keras.layers.recurrent import LSTMfrom keras.models import *from attention_utils import get_activations, get_data_recurrentINPUT_DIM = 2TIME_STEPS = 20# if True, the attention vector is shared across the input_dimensions where the attention is applied.SINGLE_ATTENTION_VECTOR = FalseAPPLY_ATTENTION_BEFORE_LSTM = False 2、数据生成函数 12345678910111213141516171819202122232425262728293031def attention_3d_block(inputs): # inputs.shape = (batch_size, time_steps, input_dim) input_dim = int(inputs.shape[2]) a = Permute((2, 1))(inputs) a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what. a = Dense(TIME_STEPS, activation='softmax')(a) if SINGLE_ATTENTION_VECTOR: a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a) a = RepeatVector(input_dim)(a) a_probs = Permute((2, 1), name='attention_vec')(a) output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul') return output_attention_mul def model_attention_applied_after_lstm(): inputs = Input(shape=(TIME_STEPS, INPUT_DIM,)) lstm_units = 32 lstm_out = LSTM(lstm_units, return_sequences=True)(inputs) attention_mul = attention_3d_block(lstm_out) attention_mul = Flatten()(attention_mul) output = Dense(1, activation='sigmoid')(attention_mul) model = Model(input=[inputs], output=output) return modeldef model_attention_applied_before_lstm(): inputs = Input(shape=(TIME_STEPS, INPUT_DIM,)) attention_mul = attention_3d_block(inputs) lstm_units = 32 attention_mul = LSTM(lstm_units, return_sequences=False)(attention_mul) output = Dense(1, activation='sigmoid')(attention_mul) model = Model(input=[inputs], output=output) return model 3、主函数12345678910111213141516171819202122232425262728293031323334353637if __name__ == '__main__': N = 300000 # N = 300 -&gt; too few = no training inputs_1, outputs = get_data_recurrent(N, TIME_STEPS, INPUT_DIM) if APPLY_ATTENTION_BEFORE_LSTM: m = model_attention_applied_before_lstm() else: m = model_attention_applied_after_lstm() m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) print(m.summary()) m.fit([inputs_1], outputs, epochs=1, batch_size=64, validation_split=0.1) attention_vectors = [] for i in range(300): testing_inputs_1, testing_outputs = get_data_recurrent(1, TIME_STEPS, INPUT_DIM) attention_vector = np.mean(get_activations(m, testing_inputs_1, print_shape_only=True, layer_name='attention_vec')[0], axis=2).squeeze() print('attention =', attention_vector) assert (np.sum(attention_vector) - 1.0) &lt; 1e-5 attention_vectors.append(attention_vector) attention_vector_final = np.mean(np.array(attention_vectors), axis=0) # plot part. import matplotlib.pyplot as plt import pandas as pd pd.DataFrame(attention_vector_final, columns=['attention (%)']).plot(kind='bar', title='Attention Mechanism as ' 'a function of input' ' dimensions.') plt.show() 4、运行结果代码中，attention_column为10，11，也就是说，label只与数据的第10，11个特征相关。从运行结果中可以看出，Attention权重成功地获取了这个信息。 ##相关代码放在代码仓库里哈，欢迎大家下载，这里附上地址：基于Kears的Attention实战]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[new Types]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F08%2F24%2Fnew-Types%2F</url>
    <content type="text"><![CDATA[我的分类是深度学习]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[“test”]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F08%2F24%2F%E2%80%9Ctest%E2%80%9D%2F</url>
    <content type="text"><![CDATA[大家好，这是我的第一个hexo!]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2FNextLegend.github.io%2F2018%2F08%2F24%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
